{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL  import Image\n",
    "import os\n",
    "\n",
    "#Directory containing the original images\n",
    "original_folder=\"IMAGES\"\n",
    "\n",
    "#directory to store resized images\n",
    "resized_folder=\"RESIZED IMAGES2\"\n",
    "\n",
    "#TARGET SIZE FOR RESIZING\n",
    "target_size=(230,230) \n",
    "\n",
    "#create the resized folder if it doesnt exist\n",
    "if not os.path.exists(resized_folder):\n",
    "    os.makedirs(resized_folder)\n",
    "total_images=1\n",
    "#itarate over each image in the original folder \n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith((\".jpg\",\".png\",\".jpeg\",\".gif\")):\n",
    "        total_images +=1\n",
    "        with Image.open(os.path.join(original_folder,filename)) as img:\n",
    "            resized_img=img.resize(target_size,Image.ANTIALIAS)\n",
    "            #save the resized image to the resized folder\n",
    "            resized_img.save(os.path.join(resized_folder,filename))\n",
    "            print(f\"Resized {filename} succesfully\")\n",
    "            \n",
    "print(f\"all {total_images} images resized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "​\n",
    "# Read the image\n",
    "image = cv2.imread(\"IMAGES/image_11.jpg\")\n",
    "​\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(\"Error: Unable to read the image.\")\n",
    "else:\n",
    "    # Output the dimensions of the image\n",
    "    print(\"Image dimensions:\", image.shape)\n",
    "​\n",
    "    # Define the coordinates of the region of interest (ROI)\n",
    "    # Adjusted coordinates within the image bounds\n",
    "    x, y, width, height = 40, 40, 120, 120 \n",
    "​\n",
    "    # Output the calculated coordinates\n",
    "    print(\"ROI coordinates:\", x, y, width, height)\n",
    "​\n",
    "    # Check if the ROI coordinates are within the bounds of the image\n",
    "    if x < image.shape[1] and y < image.shape[0]:\n",
    "        # Adjust the ROI dimensions if it exceeds the image boundaries\n",
    "        width = min(width, image.shape[1] - x)\n",
    "        height = min(height, image.shape[0] - y)\n",
    "​\n",
    "        # Crop the image\n",
    "        cropped_image = image[y:y+height, x:x+width]\n",
    "​\n",
    "        # Display the cropped image\n",
    "        cv2.imshow(\"Cropped Image\", cropped_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "​\n",
    "        # Save the cropped image\n",
    "        cv2.imwrite(\"cropped_image.jpg\", cropped_image)\n",
    "        print(\"Cropped image saved successfully.\")\n",
    "    else:\n",
    "        print(\"Error: ROI coordinates are outside the bounds of the image.\")\n",
    "​\n",
    "2.resizing\n",
    "\n",
    "we resized all images in the dataset by 230*230 pixels. Resizing ensures that all images in the dataset have same dimensions. This uniformity simplifies data preprocessing and model training, as the model does not have to handle images of different sizes.\n",
    "resizing code of all images\n",
    "from PIL  import Image\n",
    "import os\n",
    "​\n",
    "#Directory containing the original images\n",
    "original_folder=\"IMAGES\"\n",
    "​\n",
    "#directory to store resized images\n",
    "resized_folder=\"RESIZED IMAGES2\"\n",
    "​\n",
    "#TARGET SIZE FOR RESIZING\n",
    "target_size=(230,230) \n",
    "​\n",
    "#create the resized folder if it doesnt exist\n",
    "if not os.path.exists(resized_folder):\n",
    "    os.makedirs(resized_folder)\n",
    "total_images=1\n",
    "#itarate over each image in the original folder \n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith((\".jpg\",\".png\",\".jpeg\",\".gif\")):\n",
    "        total_images +=1\n",
    "        with Image.open(os.path.join(original_folder,filename)) as img:\n",
    "            resized_img=img.resize(target_size,Image.ANTIALIAS)\n",
    "            #save the resized image to the resized folder\n",
    "            resized_img.save(os.path.join(resized_folder,filename))\n",
    "            print(f\"Resized {filename} succesfully\")\n",
    "            \n",
    "print(f\"all {total_images} images resized\")\n",
    "​\n",
    "CREATING IMAGE CLASS LABEL (GROUPING IMAGES)\n",
    "We looked at every image and see the quality of each image then we put images in classes based on thier pollution level. We created three following classes.\n",
    "\n",
    "clean air class: this class contains all the image that are clean and they dont show any air pollution\n",
    "moderate polluted air class: this class contains images that have mederate air pollution\n",
    "heavy polluted air class: this class contains images that have heavy air pollution\n",
    "in each class label we put 15 images\n",
    "\n",
    "DATA FORMATTING\n",
    "After grouping the images based on their level of pollution, we converted the dataset into the COCO JSON data format. COCO provides a standardized format for representing image datasets and is commonly used for tasks such as object detection. Using COCO can increase the robustness of computer vision algorithms to unseen images.\n",
    "\n",
    "In this COCO JSON format, we assigned numerical labels to each class, with clean air labeled as 1, moderate polluted air as 2, and heavy polluted air as 3. Using numerical labels for prediction simplifies the representation of classes, making it easier for machine learning algorithms to process the data efficiently. Code we used to convert the image dataset to COCO JSON dataset format\n",
    "import json\n",
    "import os\n",
    "​\n",
    "# Define the path to your dataset directory\n",
    "dataset_dir = \"air_dataset\"\n",
    "​\n",
    "# Initialize a dictionary to store the COCO-style dataset annotations\n",
    "coco_dataset = {\n",
    "    \"info\": {\n",
    "        \"description\": \"This dataset contains images of Air Pollution for different cities in India and Nepal. The dataset is divided into two folders: Combined_Dataset and Country_wise_Dataset.\\\n",
    "                        Total number of image dataset: 12,240 Image size: 230*230\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/adarshrouniyar/air-pollution-image-dataset-from-india-and-nepal\",\n",
    "        \"version\": \"2022\",\n",
    "        \"year\": \"10/01/2022\",\n",
    "        \"contributor\": \"Adarsh Rouniyar, Sapdo Utomo, Dr. John A., Dr. Pao-Ann Hsiun\",\n",
    "        \"help\": \"Email: adarsh@csie.io\"\n",
    "    },\n",
    "    \"licenses\": [{\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)\",\n",
    "        \"url\": \"https://creativecommons.org/licenses/by-nc-sa/3.0/igo/\"\n",
    "    }],\n",
    "    \"categories\": [{\n",
    "        \"id\": 1,\n",
    "        \"name\": \"clean_air\",\n",
    "        \"supercategory\": \"pollution_level\"\n",
    "    }, {\n",
    "        \"id\": 2,\n",
    "        \"name\": \"moderate_pollution\",\n",
    "        \"supercategory\": \"pollution_level\"\n",
    "    }, {\n",
    "        \"id\": 3,\n",
    "        \"name\": \"heavy_pollution\",\n",
    "        \"supercategory\": \"pollution_level\"\n",
    "    }],\n",
    "    \"images\": [],  # Fill this with the image data\n",
    "}\n",
    "​\n",
    "# Mapping from category folder names to category IDs\n",
    "category_id_map = {\n",
    "    \"clean_air\": 1,\n",
    "    \"moderate_air\": 2,\n",
    "    \"heavy_polluted_air\": 3\n",
    "}\n",
    "​\n",
    "# Iterate over each category folder in your dataset directory\n",
    "for category_folder, category_id in category_id_map.items():\n",
    "    category_path = os.path.join(dataset_dir, category_folder)\n",
    "    if os.path.isdir(category_path):\n",
    "        # Iterate over the image files in the category folder\n",
    "        for filename in os.listdir(category_path):\n",
    "            if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                # Construct the path to the image file\n",
    "                image_path = os.path.join(category_path, filename)\n",
    "                \n",
    "                # Add the image to the COCO-style dataset\n",
    "                coco_dataset[\"images\"].append({\n",
    "                    \"id\": len(coco_dataset[\"images\"]) + 1,\n",
    "                    \"file_name\": filename,\n",
    "                    \"category_id\": category_id\n",
    "                })\n",
    "​\n",
    "# Save the COCO-style dataset annotations to a JSON file\n",
    "annotations_path = \"annotations.json\"\n",
    "with open(annotations_path, \"w\") as f:\n",
    "    json.dump(coco_dataset, f)\n",
    "​\n",
    "print(\"done\")\n",
    "​\n",
    "CHALLENGES WE FACED WHEN WE WERE DOING THIS TASK\n",
    "Data collection: we downloaded a dataset from Kaggle, but it was too big close to 1GB in size. we struggled to download the dataset due to poor internet connection\n",
    "\n",
    "Image labeling: Sorting each image into its pollution level category was quite a task. We had to carefully look at each image and decide where it belongs. This took a lot of time and effort because we had to do it manually.\n",
    "\n",
    "Data formatting: Getting the labeled images into the right format (COCO JSON) was another challenge. We had to rearrange the data to fit the format properly. It was an important step for training and testing our model, but it wasn't easy and required a lot of attention to detail. -feature engineering:since it was our first time to do this kind of task,it was difficult to choose which tools are suitable for the task ,but in the end we found a solution to complete the feature engineering task\n",
    "\n",
    "​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
